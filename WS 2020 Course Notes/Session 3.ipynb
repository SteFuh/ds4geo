{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPNjSk80vplFAHjpEuqSAA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ds4geo/ds4geo/blob/master/WS%202020%20Course%20Notes/Session%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2t-BuqUeum_"
      },
      "source": [
        "# **Data Science for Geoscientists - Winter Semester 2020**\n",
        "# **Session 3 - Pandas - 21st October 2020**\n",
        "\n",
        "Last week we covered data handling and indexing using python's in-built list and dictionary objects. This week we will cover indexing using Pandas which builds directly upon list and dictionary indexing. This session is focused on practical example excercises, mostly with student submitted data (from assignment 1). After this session, you should feel comfortable handling data with Pandas as the basis for more advanced topics in future sessions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auBS4Nqjfhf-"
      },
      "source": [
        "# Part 3.1 - Review of plotting assignment - *Discussion*\n",
        "We will review and discuss the assignment submissions from last week.\n",
        "Students will review and discuss improvements to each other's plots/visualisations.\n",
        "\n",
        "**General Feedback**\n",
        "* Lots of ambitious visualisations!\n",
        "* Everyone who submitted provided what was asked.\n",
        "* Helpful to include \"Open in Colab\" button when saving to GitHub.\n",
        "* Be liberal with comments. Consider both comments which explain what individual lines do (if they are not so simple they are obvious), but also comments for blocks indicating the purpose of several lines of code.\n",
        "* Don't be afraid to use Text cells if appropriate (more in future assignments).\n",
        "* Link to data in the public repository to avoid having expiring tokens and 404 errors (that's why I copied all the submitted data there).\n",
        "* You are encouraged to look at the other submissions for ideas and coding examples. You can search the repository for particular code to see examples of a particular function, e.g. search for \"geopandas\" to see submissions which include the library geopandas.\n",
        "\n",
        "**Highlights to show/discuss**\n",
        "* https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assigment_2_Christoph_Daxer.ipynb\n",
        "* https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Tim_Philipp.ipynb\n",
        "* https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_JanaMolenaar.ipynb\n",
        "* https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Tanguy_Racine.ipynb\n",
        "* https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_AnnaSieberer.ipynb\n",
        "* https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Patrick_Oswald.ipynb\n",
        "\n",
        "**Good examples**\n",
        "* Working with geospatial data:\n",
        " * https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assigment_2_Christoph_Daxer.ipynb\n",
        " * https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Tim_Philipp.ipynb\n",
        " * https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Tanguy_Racine.ipynb\n",
        " * https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_AnnaSieberer.ipynb\n",
        "* Pandas functionality:\n",
        " * \"rolling\" and \"fillna\": https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Patrick_Oswald.ipynb\n",
        "* Flow control:\n",
        " * https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_JanaMolenaar.ipynb\n",
        " * https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Thomas_Klotz.ipynb\n",
        " * https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment2_Andrea_Franco.ipynb\n",
        "* Databases:\n",
        " * sqlite3: https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Tanguy_Racine.ipynb\n",
        " * NetCDF4: https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assigment_2_Christoph_Daxer.ipynb\n",
        "* Other:\n",
        " * Stereonets: https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Tanguy_Racine.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRnmy7QfyAH"
      },
      "source": [
        "# Part 3.2 - Pandas indexing\n",
        "As we've seen in previous weeks, we can easily select a column of a pandas DataFrame using `[\"column name\"]` notation (i.e. just like dictionary indexing).\n",
        "\n",
        "Pandas offers two approaches for more complex indexing of data rows and columns: iloc and loc.\n",
        "\n",
        "See here: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
        "\n",
        "iloc is purely integer based indexing, just like python lists.\n",
        "loc is purely label based indexing which uses column names and the row index.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrtVq_TIaj_o"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-vL9m7HcJso"
      },
      "source": [
        "## 3.2.1 Pandas integer indexing (iloc)\n",
        "We start with iloc as it is very similar to what we covered last week with lists. However, indexing by label (loc) is very often more useful, so we will cover loc (see below) in more detail than iloc.\n",
        "\n",
        "**Integer row indexing**\n",
        "\n",
        "Integer indexing of rows works exactly like python lists except adding `.iloc` between the object and the indexing brackets `[  ]`:\n",
        "\n",
        "    dat.iloc[0] # first row of a dataframe\n",
        "    dat.iloc[0:5] # first 5 rows of dataframe\n",
        "    dat.iloc[-1] # last row of dataframe\n",
        "\n",
        "**Integer row and column indexing**\n",
        "\n",
        "You can select columns as well as rows by including a comma:\n",
        "\n",
        "    dat.iloc[0, 0:5] # first row and first 5 columns\n",
        "    dat.iloc[:, 2] # all rows and 3rd column\n",
        "    dat.iloc[:, -1] # all rows and last column\n",
        "    dat.iloc[-4:, 2:-2] # last 4 rows and 3rd to 2nd to last columns\n",
        "    \n",
        "\n",
        "https://doi.pangaea.de/10.1594/PANGAEA.922011?format=textfile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_OLuKu8NmqA"
      },
      "source": [
        "### 3.2.1.1 - Selecting single rows and ranges - NGRIP\n",
        "Last week when plotting NGRIP and LR04 on the same plot, it is helpful to automatically determine the oldest date in the NGRIP data to automatically scale the plot axis limits.\n",
        "\n",
        "**Task**\n",
        "\n",
        "Load LR04 and NGRIP (see previous sessions) and print the age of the last (oldest) sample in each dataset. \n",
        "\n",
        "Also, select just the first 1000 rows of each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjoyq0GvPr2o"
      },
      "source": [
        "LR04 = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/LR04stack.txt\", sep=\"\\t\", header=3)\n",
        "LR04.columns = [\"Age\", \"d18O\", \"error\"]\n",
        "NGRIP = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/NGRIP_chronology_20.tab\", sep=\"\\t\", header=20)\n",
        "NGRIP.columns = [\"Age\", \"Depth\", \"Age_error\", \"d18O\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ho-NUrpjCV0",
        "outputId": "a225ba09-d0ee-411b-83e7-ecc67a742596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "LR04"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>d18O</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>5300.0</td>\n",
              "      <td>2.91</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2111</th>\n",
              "      <td>5305.0</td>\n",
              "      <td>2.79</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2112</th>\n",
              "      <td>5310.0</td>\n",
              "      <td>2.79</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113</th>\n",
              "      <td>5315.0</td>\n",
              "      <td>2.84</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2114</th>\n",
              "      <td>5320.0</td>\n",
              "      <td>2.91</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2115 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Age  d18O  error\n",
              "0        0.0  3.23   0.03\n",
              "1        1.0  3.23   0.04\n",
              "2        2.0  3.18   0.03\n",
              "3        3.0  3.29   0.03\n",
              "4        4.0  3.30   0.03\n",
              "...      ...   ...    ...\n",
              "2110  5300.0  2.91   0.06\n",
              "2111  5305.0  2.79   0.04\n",
              "2112  5310.0  2.79   0.09\n",
              "2113  5315.0  2.84   0.07\n",
              "2114  5320.0  2.91   0.09\n",
              "\n",
              "[2115 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvug14HJQUdH"
      },
      "source": [
        "### 3.2.1.2 - Selecting ranges of rows and columns - New Hebrides lava\n",
        "**Task**\n",
        "\n",
        "Select just the element data from this lava geochemistry dataset (loaded below), and then just the first 10 samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBWX56_4QcAA"
      },
      "source": [
        "nh = pd.read_csv(\"https://doi.pangaea.de/10.1594/PANGAEA.922011?format=textfile\", sep=\"\\t\", header=105)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOovUOiMjDe9"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFlgzv8OPsZT"
      },
      "source": [
        "### 3.2.1.3 - Selecting ranges after sort - Alpine/Austrian Glacier Inventory\n",
        "\n",
        "**Task**\n",
        "\n",
        "Print the names of the top 5 glaciers in the dataset in terms of size. Consider using `pd.sort_values`.\n",
        "\n",
        "Challenge: for the top 5 glaciers, print also their area in hectares, and proportion of the total area of the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9FLc1uFhxH3"
      },
      "source": [
        "glaciers = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/student_submitted_data/Giulia_Bertolotti/GI_4_2015/GI_4_2015.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dhAoM6IjIqH"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvc8cwNXlp-0"
      },
      "source": [
        "### 3.2.1.4 - Selecting values after sort - New Caledonia lava chemistry\n",
        "**Task**\n",
        "\n",
        "Using the same dataset as in 3.2.1.2 (above), print the \"Area\", and Rock type of the most Calcium rich lava."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqhT15NGlwB5"
      },
      "source": [
        "nh = pd.read_csv(\"https://doi.pangaea.de/10.1594/PANGAEA.922011?format=textfile\", sep=\"\\t\", header=105)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBApqdIbcVRW"
      },
      "source": [
        "## 3.2.2 - Pandas label based indexing (loc)\n",
        "\n",
        "Pandas also allows indexing based on the row or column labels. The row labels are known as the index.\n",
        "\n",
        "When you load data, the index is usually just row numbers of the input file, but sometimes it is set automatically. Usually it is valuable to deliberately set the index to a useful column such as age, depth or distance.\n",
        "\n",
        "Once this is done, indexing with `dat.loc[...]` allows selecting data based on the index values (i.e. not row numbers/integers) directly.\n",
        "\n",
        "***EXAMPLES***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HluNff-VTzC"
      },
      "source": [
        "### 3.2.2.1 - Indexing by age vs depth - NGRIP\n",
        "\n",
        "**Task**\n",
        "\n",
        "Set the index of the NGRIP data to the age as shown below. Then select the period between 9 and 15 ka and plot the d18O to see the last deglaciation & Younger Dryas.\n",
        "\n",
        "Do the same as above but setting the index to depth. Then select and plot the top 250 meters of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zun297djZEI"
      },
      "source": [
        "NGRIP.index = NGRIP[\"Age\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8hRCBwElwEV"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKh5YQKSLf-z"
      },
      "source": [
        "### 3.2.2.2 - Hekla tephra data - Un-ordered data\n",
        "The index doesn't need to be unique. In some cases, setting an index to a category is a quick way to select different parts of an un-ordered dataset.\n",
        "\n",
        "Consider this dataset of tephra chemistry from different eruptions of Hekla.\n",
        "\n",
        "**Task**\n",
        "\n",
        "Set the index to the eruption name and select just the element data for a particular eruption.\n",
        "\n",
        "Challenge: calculate chemistry statistics for the selected eruption."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V8KKlGiLW7G"
      },
      "source": [
        "hekla = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/student_submitted_data/Giulia_Bertolotti/Hekla_Tephra_GIulia\",sep=\"\\t\",decimal=\",\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLY-BoJqMAR-"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjSLyYZwcgXJ"
      },
      "source": [
        "## 3.2.3 - Datetime based indexing\n",
        "\n",
        "Pandas also allows columns with date/time data to be set as an index. If properly stored as pandas datetime data type, indexing based on datetime indexes allows extra functionality on top of the plain .loc system. For example:\n",
        "\n",
        "    dat.loc[\"2015\"] # select all data from year 2015\n",
        "    dat.loc[\"2016-01\"] # select all data from Jan 2016\n",
        "    dat.loc[\"2018\":] # select all data from 2018 onwards\n",
        "    dat.loc[\"2018\":\"2019\"] # select all data from 2018 until 2019 (inclusive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcCyn1zo5dyZ"
      },
      "source": [
        "### 3.2.3.1 - Rossalm weather data\n",
        "The Rossalm dataset is the largest (as far as I can tell) student uploaded dataset/timeseries in the student submitted data repository.\n",
        "\n",
        "If you run the first cell below, you'll see that the datetime column of the dataframe is type \"object\" instead of \"datetime\". Therefore, we first need to convert it to datetimes which Pandas recognises using pd.to_datetime (see below).\n",
        "\n",
        "**Task**\n",
        "\n",
        "Set the datetime column as the index of the Rossalm dataset.\n",
        "Use indexing and aggregation functions (e.g. mean, max, min, etc. - `rossalm.loc[\"2016\"].mean()`) to describe and explore several different parts of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgbGKF2G2Z1b",
        "outputId": "c16ff715-b8be-4abe-a34f-180b7755e47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rossalm = pd.read_csv(r\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/student_submitted_data/Rossalm_HS_LT_LF_Tim_Philipp.csv\")\n",
        "rossalm.columns = [\"datetime\", \"snow\", \"temp\", \"humid\"]\n",
        "rossalm.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 324425 entries, 0 to 324424\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count   Dtype  \n",
            "---  ------    --------------   -----  \n",
            " 0   datetime  324425 non-null  object \n",
            " 1   snow      324423 non-null  float64\n",
            " 2   temp      324424 non-null  float64\n",
            " 3   humid     324423 non-null  float64\n",
            "dtypes: float64(3), object(1)\n",
            "memory usage: 9.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGYVmtmz2dJa",
        "outputId": "b2810e48-fbf6-4d55-949e-5e8ebee32f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Convert the datetime to \"real\" pandas datetime\n",
        "rossalm[\"datetime\"] = pd.to_datetime(rossalm.datetime)\n",
        "rossalm.info()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 324425 entries, 0 to 324424\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count   Dtype         \n",
            "---  ------    --------------   -----         \n",
            " 0   datetime  324425 non-null  datetime64[ns]\n",
            " 1   snow      324423 non-null  float64       \n",
            " 2   temp      324424 non-null  float64       \n",
            " 3   humid     324423 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(3)\n",
            "memory usage: 9.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNfuCZVxk1em"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdxTQGn8CYHN"
      },
      "source": [
        "## 3.2.4 - Boolean indexing and Query\n",
        "** Boolean Indexing**\n",
        "\n",
        "Pandas loc and iloc indexing also accepts arrays of boolean values, i.e. `True` or `False`.\n",
        "\n",
        "Boolean arrays can be created using comaprison operators (`== ,!=, >, >=, <, <=`) or their pandas method equivalents (`df.eq, df.ne, df.le, df.lt, df.ge, df.gt`). Examples using the hekla dataset are below.\n",
        "\n",
        "Boolean arrays can be combined using logical operators (`&, |, ~`) or numpy logical functions (`np.logical_and, np.logical_or, np.logical_not, np.any, np.all`).\n",
        "\n",
        "** Pandas Query**\n",
        "\n",
        "Pandas also has a method called `.query` which allows similar selecting of data as boolean indexing. They are largely interchangable, but boolean indexing is preferred if it is pre-calculated and combined in complex ways. Query allows simpler syntax but is less flexible. It is worth being familiar with both approaches.\n",
        "\n",
        "Examples of both boolean indexing and equivalent query selection are shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3qkAGIPsgwD"
      },
      "source": [
        "### 3.2.4.1 - Hekla tephra data boolean indexing and query examples\n",
        "Examples of boolean indexing and equivalent query selections are shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dctmkNfusseH"
      },
      "source": [
        "# Select a particular Eruption (e.g. if Eruption isn't the index)\n",
        "hekla.loc[hekla[\"Eruption\"] == \"Hekla 4\"]\n",
        "hekla.query(\"Eruption == 'Hekla 4'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go7KyBkItSCf"
      },
      "source": [
        "# Select rows with CaO greater than 5 and Na2O greater than 3\n",
        "hekla.loc[(hekla[\"CaO\"] > 5) & (hekla[\"Na2O\"] > 3)]\n",
        "hekla.query(\"CaO > 5 & Na2O > 3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va8b_xXKhLCJ"
      },
      "source": [
        "# Select rows with K2O greater than 3 or Na2O greater than 5\n",
        "hekla.loc[(hekla[\"K2O\"] > 3) | (hekla[\"Na2O\"] > 5)]\n",
        "hekla.query(\"KaO > 3 | Na2O > 5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bDQ9bbLv8HT"
      },
      "source": [
        "###3.2.4.2 - Alpine lake data\n",
        "The dataset includes metadata such as name, area, depth, etc. for lakes in and around the Alps.\n",
        "\n",
        "**Tasks**\n",
        "* List the lakes with a volume of > 10,000 km3.\n",
        "* How many lakes in Switzerland are above 2,000 m elevation.\n",
        "* List the top 5 lakes in terms of area whose average depth is below sea level.\n",
        "* Compare the number, volume and total area of lakes in Austria vs Switzerland.\n",
        "* Continue your own analysis. Report something you find interesting.\n",
        "\n",
        "Try to do the above with both boolean indexing and `.query`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1_JYuKZv80_"
      },
      "source": [
        "lakes = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/student_submitted_data/ChristophDaxer/Lakes_Alps_metadata.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwx1dGyDRVSz"
      },
      "source": [
        "# 3.3 - Practicing flow control\n",
        "Loops combined with if statements are a powerful tool which can be applied in many situations. In many cases in data analysis, there are alternative and more efficient ways to achieve something than loops, but their versatility means they are nevertheless important to master, and enable large and complex analyses to be repeated automatically.\n",
        "\n",
        "The below excercises demonstrate a number of possible applications of loops and if statements relevant to data science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnNZQBzxRXbH"
      },
      "source": [
        "## 3.3.1 Looping for loading or organising data\n",
        "The following dataset contains several different temp-salinity depth profiles. We can use loops to separate the different profiles so we can split them into individual dataframes or groupings.\n",
        "\n",
        "**Task 1**\n",
        "\n",
        "Create a list of Dataframes, one for each profile. The profiles are identified by unique values in the \"Event\" column. You will need to use a for loop over the unique values in the Event column. Use `dat.unique()` on a column to get the unique values. Create a blank list and use `.append()` to add to it on each iteration of your loop. \n",
        "\n",
        "You have several options of how to select all data from each profile: 1. setting \"Event\" as the index, 2. using boolean indexing or 3. using the `dat.query()` method.\n",
        "\n",
        "Note: there are other ways of achieving this other than loops. If you find one, feel free to use it, but also try using a loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2I2NE69TeDX"
      },
      "source": [
        "kol_dat = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/student_submitted_data/Temp-Salinity-North%20of%20Iceland_Johanna_P%C3%B6ll.csv\", sep=\";\", header=10)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVqg4Ub6T36F"
      },
      "source": [
        "kol_dat[\"Event\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMdHKQuFW85B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ1K3r8BrcQs"
      },
      "source": [
        "**Task 2**\n",
        "\n",
        "You will see that the event names follow several patterns in terms of the first few characters (KN, B7, ALL, KB). Assume these profiles should be grouped on this basis. Make a series of lists, each one containing all the profiles associated with a certain naming pattern."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AYos9rXXDt"
      },
      "source": [
        "# excercise: use If to split into several lists based on the name of the profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8JfDhmVX2bz"
      },
      "source": [
        "# Further excercises:\n",
        "# Look at the following datasets. Split them as appropriate and plot them as above\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASwF_wndZc4L"
      },
      "source": [
        "## 3.3.2 Loops for analysing data\n",
        "In a similar way to above, automatic splitting of the data also allows statistics on each split to be calculated.\n",
        "\n",
        "The dataset below contains data on leaves of different trees around Innsbruck.\n",
        "\n",
        "**Task**\n",
        "\n",
        "For each tree species (type), print the average leaf length, width and leaf-width ratio.\n",
        "\n",
        "Your loop should be similar to that in 3.3.1 except with the statistical calculations and print instead of `.append()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyu3qUgtAgL"
      },
      "source": [
        "leaves = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/student_submitted_data/ChristophDaxer/Leaves_2013.csv\",encoding = 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K20CqW3ZmK7"
      },
      "source": [
        "## 3.3.3 Loops for plotting data\n",
        "Loops also allow automation (in a tidy way) of complicated visualisations. For example, plotting different parts of a dataset in different styles/colours.\n",
        "\n",
        "**Task 1**\n",
        "\n",
        "Make a scatter plot of FeO vs Na2O for the hekla dataset from 3.2.2.2.\n",
        "Plot each eruption as a different colour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyuZ_RLi2VMc"
      },
      "source": [
        "hekla"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNxkNqKyUuaf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbFWfgFUlNyV"
      },
      "source": [
        "**Task 2**\n",
        "\n",
        "Plot each year of the Rossalm (see 3.2.3.1) dataset overlapping on a single x axis. Find a way to plot the data to clearly show the year 2018 and how it compares in general to other years."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp-rVKCsYzfL"
      },
      "source": [
        "rossalm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwiwQVrzpAzr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ym9fnKSAJeo"
      },
      "source": [
        "# 3.4 - For those wanting a challenge - *Optional*\n",
        "These tasks are intended to be challenging and little assistance is given. Pick either task.\n",
        "\n",
        "**Task A - Geological summary of the Bundeslande**\n",
        "\n",
        "Create a visualisation indicating the proportion of each Austrian federal state covered by particular types of geology.\n",
        "\n",
        "A geological map of Austria can be accessed here: https://gis.geologie.ac.at/inspire/download/ge200_einheiten_epsg4258.zip\n",
        "\n",
        "See also: https://gis.geologie.ac.at/inspire/download/DownloadServiceFeed.xml\n",
        "\n",
        "Files containing administrative regions, including Bundesland level available here:\n",
        "http://gisco-services.ec.europa.eu/distribution/v2/nuts/download/ref-nuts-2021-03m.geojson.zip\n",
        "\n",
        "You can download these files using `!wget` and then `!unzip` and load them using geopandas. You can install geopandas simply with `!pip install geopandas`.\n",
        "\n",
        "See also the following assignment submission with examples of the above: https://github.com/ds4geo/ds4geo_ws2020/blob/master/Assignments/Session%202/Assignment_2_Tim_Philipp.ipynb\n",
        "\n",
        "**Task B - Summary of the geology of Austrian wines**\n",
        "\n",
        "Determine the proportion of Austria's vineyards lying on different bedrock types and visualise the results\n",
        "\n",
        "See above for geological map and how to download and load the data.\n",
        "\n",
        "A shapefile of all vineyards in Austria is available here: https://github.com/ds4geo/ds4geo/blob/master/data/geospatial/AT_wine/AT_wine.zip?raw=true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DQo8JMmvCeS"
      },
      "source": [
        "# 3.5 - Week 3 Assignment\n",
        "\n",
        "Data contains hidden stories. Part of data science (arguably quantitative science in general!) is to find and tell those stories. Jupyter notebooks provide a perfect tool for data story-telling in allowing text, images, code and code results (e.g. plots) to be combined.\n",
        "\n",
        "**Task**\n",
        "\n",
        "Create a Jupyter notebook where you tell the story of what it is like to live in 2 different cities in terms of the weather. Pick 2 from Innsbruck, London, Sydney, Tehran and Singapore.\n",
        "* Daily weather data for these cities for 2015 to 2019 is provided (see below).\n",
        "* You should not use any source of information (including personal experience) other than the data provided and your analysis of it.\n",
        "* You are free to tell the story as you wish in terms of content and style. Your audience is the other course participants.\n",
        "* Do not just summarise the data, tell a story. You do not need to use all of the available data.\n",
        "* Length depends on how one tells the story, but including 10 lines of code is too short, and 100 is too long.\n",
        "* Use Pandas to handle and analyse the data. Use the built in help, online Pandas help docs, and google to figure out how to perform your analysis. Note down anything you wish to do but cannot figure out how to do.\n",
        " * Hint: .groupby(), .mean(), .sum(), .count(), etc. will be useful!\n",
        "\n",
        "**Data**\n",
        "\n",
        "Pandas readable csv files are located here:\n",
        "* Innsbruck:\n",
        " * Readable: https://github.com/ds4geo/ds4geo/blob/master/data/timeseries/meteo/Innsbruck_weather_2015-19.csv\n",
        "  * Raw: https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/meteo/Innsbruck_weather_2015-19.csv\n",
        "* London:\n",
        " * Readable: https://github.com/ds4geo/ds4geo/blob/master/data/timeseries/meteo/London_weather_2015-19.csv\n",
        "  * Raw: https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/meteo/London_weather_2015-19.csv\n",
        "* Sydney:\n",
        " * Readable: https://github.com/ds4geo/ds4geo/blob/master/data/timeseries/meteo/Sydney_weather_2015-19.csv\n",
        "  * Raw: https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/meteo/Sydney_weather_2015-19.csv\n",
        "* Tehran:\n",
        " * Readable: https://github.com/ds4geo/ds4geo/blob/master/data/timeseries/meteo/Tehran_weather_2015-19.csv\n",
        "  * Raw: https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/meteo/Tehran_weather_2015-19.csv\n",
        "* Singapore:\n",
        " * Readable: https://github.com/ds4geo/ds4geo/blob/master/data/timeseries/meteo/Singapore_weather_2015-19.csv\n",
        "  * Raw: https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/meteo/Singapore_weather_2015-19.csv\n",
        "\n",
        "The data was downloaded from https://rp5.ru/ and pre-processed from hourly to daily data.\n",
        "\n",
        "\n",
        "**Submission**\n",
        "* Submit the assignment here: https://github.com/ds4geo/ds4geo_ws2020/tree/master/Assignments/Session%203\n",
        "* Create a new Colab notebook via Google Drive, then save it to the submission repository using \"save a copy to GitHub\". See here:\n",
        " * https://github.com/ds4geo/ds4geo/blob/master/Github%20Assignment%20Readme.md\n",
        "* The **deadline** is 23:59 on 3rd November 2020.\n",
        "* This assignment comprises 5% of the assessment for the course. Marks are awarded for clear, effective and interesting data driven story telling.\n",
        "\n",
        "Submitted notebooks will be available to the whole class, and will be discussed in session 4. The assignment to session 5 will build upon this assignment.\n",
        "\n"
      ]
    }
  ]
}