{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS4GEO_L5.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaynrmXSecX5vJZC2A41EO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ds4geo/ds4geo/blob/master/WS%202020%20Course%20Notes/Session%205.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kH3uXM6ub2G"
      },
      "source": [
        "# To Do\n",
        "**High priority**\n",
        "* time series intro/interpolation mini-lecture and notes\n",
        "* Scipy mini lecture\n",
        "\n",
        "* Cave excercise short intro notes\n",
        "\n",
        "* Intro to data filtering lecture and notes\n",
        "* Advanced filtering mini-lecture and notes\n",
        "\n",
        "\n",
        "**Other**\n",
        "* Submission method\n",
        "* References\n",
        "\n",
        "\n",
        "* Create separate solutions notebook\n",
        "* Enable output cells\n",
        "* Final go-through and checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcdW54CLeSyH"
      },
      "source": [
        "# **Data Science for Geoscientists - Winter Semester 2020**\n",
        "# **Session 5 - Time Series - 4th November 2020**\n",
        "In the previous sessions and assignments, we've covered basic data handling, maniuplation and visualisation. In this session we will go deeper into working with time series, especially two frequently encountered topics: interpolation and filtering. We will use a monitoring dataset from Spanagel cave."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE7qVuiWebgJ"
      },
      "source": [
        "# Part 5.1 - Walkthrough of Session 4 LA-ICPMS excercise - *Walkthrough/Discussion*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVLAWrSYebwR"
      },
      "source": [
        "# Part 5.2 - Cave monitoring data excercise part 1 - *Workshop*\n",
        "We will work with cave monitoring data from Spanagel cave collected by Paul TÃ¶chterle and the UIBK Quaternary Research Group.\n",
        "\n",
        "The data was collected to understand the cave circulation which is important for interpreting speleothem based palaeoclimate records from the cave. Three types of data were collected: 1. outside air temperature, 2. cave temperature, and 3. cave CO2 concentration, oxygen and carbon isotope ratios.\n",
        "\n",
        "The following poster gives an explanation of the project and the data: https://github.com/ds4geo/ds4geo/blob/master/data/timeseries/Spanagel_Poster.pdf\n",
        "\n",
        "We will load the data and perform some important processing steps to enable further comparative analysis of the three datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G28TpnTbyIUf"
      },
      "source": [
        "## Part 5.2.1 - Load the cave monitoring data\n",
        "Three datasets are available: Cave temperature, Outside air temperature, and Cave CO2 measurements (concentration, d13C, d18O).\n",
        "\n",
        "The data sets are located as follows:\n",
        "* Cave air temperature:\n",
        " * \"https://github.com/ds4geo/ds4geo/raw/master/data/timeseries/Au%C3%9Fenluft%2BEingangslabyrinth.xlsx\"\n",
        " * Sheet: \"Daten3\"\n",
        " * Time column: A, data column: G\n",
        "* Outside air temperature:\n",
        " * \"https://github.com/ds4geo/ds4geo/raw/master/data/timeseries/Au%C3%9Fenluft%2BEingangslabyrinth.xlsx\"\n",
        " * Sheet: \"Daten3\"\n",
        " * Time column: I, data column: J\n",
        "* Cave CO2 measurements:\n",
        " * https://github.com/ds4geo/ds4geo/raw/master/data/timeseries/CO2%20_compiled.xlsx\"\n",
        " * Sheet: \"Data Stream (2)\n",
        " * Time column: A, d13C column: C, d18O column: D, ppm CO2 column: E\n",
        "\n",
        "**Task**\n",
        "Load all three datasets using Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY-jL4T7yN_q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMedLSvQSvhm"
      },
      "source": [
        "##Part 5.2.2 - Plot the data to get an overview\n",
        "Make a few plots to get an overview of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTN3n8OFTJf8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF5I_YqQTJ1o"
      },
      "source": [
        "##Part 5.2.3 - Create a sub-set of the data for analysis\n",
        "Create a sub-set of each dataset containing only the data between September and November 2015.\n",
        "\n",
        "Hint: set the dataset indexes to the time column as we did in session 3 and use .loc to easily select time ranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxOtBn2DbaXx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL1vcb6rUas3"
      },
      "source": [
        "## Part 5.2.4 - Check the number of samples/sampling rate\n",
        "To do further analysis, it helps if all three datasets have the same amount of data with corresponding timestamps and sampling rate. Check the lenght of each and the sampling rate of each.\n",
        "\n",
        "Hint: you will need to using indexing, and the `DataFrame.value_counts()` method will be useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNtY-dIbUagp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG15InoAecIg"
      },
      "source": [
        "# Part 5.3 - Timeseries and interpolation theory - *Mini-Lecture*\n",
        "You will see from the workshop that the rate of data sampling is different in each of the datasets, and is even inconsistent within some of them. To analyse them further, we need them to be at the same rate, so we need to resample or interpolate them.\n",
        "\n",
        "*add mini lecture notes*\n",
        "\n",
        "*time series background*\n",
        "\n",
        "*resampling vs interpolation*\n",
        "\n",
        "*briefly: linear interp, spline interp, nearest, etc.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tseaDm4kgk-t"
      },
      "source": [
        "# Part 5.4 - Introduction to SciPy - *Mini-lecture*\n",
        "While Numpy handles multidimensional arrays and various mathematical operations on them, the SciPy library provides a wide range of more advanced functionality which is particularly useful for scientific data analysis.\n",
        "\n",
        "It includes for example modules concerning linear algebra, regression/fitting, integration, signal processing, image manipulation and statistics.\n",
        "\n",
        "SciPy can also refer to a collection of related libraries including Numpy, Pandas, Matplotlib and the SciPy library itself.\n",
        "\n",
        "It contains a module called scipy.interpolate which we will use in the next section.\n",
        "\n",
        "See here:\n",
        "https://www.scipy.org/scipylib/index.html\n",
        "\n",
        "The SciPy cookbook has many useful examples of using SciPy functions:\n",
        "https://scipy-cookbook.readthedocs.io/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj9tKXMPgxWR"
      },
      "source": [
        "#Part 5.5 - Cave monitoring data excercise part 2 (resampling/interpolation) - *Workshop*\n",
        "We will now resample the datasets so they have the same sampling rate, and that the data corresponds directly in terms of sampling time. We will resample everything to the same sampling rate and times as the cave temperature record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsIk7P6_kO7v"
      },
      "source": [
        "# For all of the below sections we will need the SciPy Interpolate module:\n",
        "from scipy import interpolate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNj-z34PFQt2"
      },
      "source": [
        "## Part 5.5.1 - Upsampling outside air temperature\n",
        "The outside air temperature is sampled at a lower rate than the cave temperature, therefore we need to upsample the outside air temperature record.\n",
        "\n",
        "Re-write the following pseudo-code to perform resampling by linear interpolation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59ilfSVJFcHG"
      },
      "source": [
        "'''\n",
        "1. Create an interpolation object containing the outside air temperature data where:\n",
        "We use the object \"interp1d\" (actually a class) from the Scipy interpolation \n",
        "<A> is the time column of the outside air temp data\n",
        "   we cannot interpolate using times directly, so \"to_numpy().astype(float) is a trick to convert the times to decimal numbers\"\n",
        "<B> is the temperature column outside air temp data\n",
        "<C> is the type of interpolation - look at the in interp1d help documentation\n",
        "<D> is the variable name to give to the interpolation object\n",
        "'''\n",
        "# <D> = interpolate.interp1d(<A>.to_numpy().astype(float), <B>, kind=<C>)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JnPvNbeiEWr"
      },
      "source": [
        "'''\n",
        "2. Perform the interpolation by providing the times from the cave temperature\n",
        "data set. These are the times where we want to calculate surface air temperatures.\n",
        "<E> is the time column of the cave temp record, converted to decimal numbers as\n",
        "     in <A>\n",
        "<F> is the resampled time-series\n",
        "'''\n",
        "#<F> = <D>(<E>)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxcf3y9Ii4Dz"
      },
      "source": [
        "'''\n",
        "3. Plot the resampled result and compare it to the original.\n",
        "It will be helpful to visualise the datapoints themselves, so use data markers\n",
        "in the plot.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C983bl6nFcei"
      },
      "source": [
        "#ANSWErS\n",
        "interpf = interpolate.interp1d(air_select.time.to_numpy().astype(float), air_select.air_temp, kind=\"linear\", fill_value=\"extrapolate\")\n",
        "air_interp = interpf(cave_select.time.to_numpy().astype(float))\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "ax.plot(cave_select.index, air_interp, \"x-\")\n",
        "ax.plot(air_select.index, air_select.air_temp, \"o\")\n",
        "ax.set_xlim(datetime.date(2015,10,15), datetime.date(2015,10,16))\n",
        "ax.set_ylim(-4, 3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15APgdD3jssA"
      },
      "source": [
        "##Part 4.5.2 - Downsample the cave CO2 data\n",
        "The cave CO2 data is at a much higher and variable sampling rate, so we will downsample it to the cave temperature sampling rate/timings.\n",
        "\n",
        "Use the previous section as a guide. You will need to separately interpolate the CO2 concentration, the d18O and d13C data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB8XGG_vkGrO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wupw6hB6l7j5"
      },
      "source": [
        "##Part 4.5.3 - Visualise data relationships.\n",
        "Now the data is directly comparable, we can easily create some simple visualisations (or calculate statistics).\n",
        "\n",
        "Try making a scatter plot(s) of CO2 concentration vs surface temperature, cave temperature, and the difference between cave and surface temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzH6-dD5WyA1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGCvWwQ5WybE"
      },
      "source": [
        "### ANSWER\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "ax.scatter( intp_air[0]-cave_select.cave_temp, intp_co2[0], marker=\"x\")\n",
        "#ax.scatter( intp_air[0], intp_co2[0], marker=\"x\")\n",
        "ax.set_ylim([375, 450])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L22LdVA_kHD3"
      },
      "source": [
        "## Part 4.5.4 - Test interpolation methods\n",
        "A number of interpolation methods exist besides linear interpolation. Experiment with and compare the different methods provided by interp1d. Which do you think are most appropriate in this context for the up- and downsampling and why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4GfjIBSkK7R"
      },
      "source": [
        "### ANSWERS\n",
        "# Testing upsampling of air temps\n",
        "kinds = [\"linear\", \"nearest\", \"zero\", \"slinear\", \"quadratic\", \"cubic\"]#, \"previous\", \"next\"]\n",
        "intp_air = []\n",
        "for k in kinds:\n",
        "  interpf = interpolate.interp1d(air_select.time.to_numpy().astype(float), air_select.air_temp, kind=k, fill_value=\"extrapolate\")\n",
        "  air_interp = interpf(cave_select.time.to_numpy().astype(float))\n",
        "  intp_air.append(air_interp)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "for i,l in zip(intp_air, kinds):\n",
        "  ax.plot(cave_select.index, i, \"x-\", label=l)\n",
        "ax.plot(air_select.index, air_select.air_temp, \"o\")\n",
        "ax.set_xlim(datetime.date(2015,10,15), datetime.date(2015,10,16))\n",
        "ax.set_ylim(-4, 3)\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wytscRkUlA04"
      },
      "source": [
        "### ANSWerS\n",
        "# Downsampling of co2 data\n",
        "kinds = [\"linear\", \"nearest\", \"zero\", \"slinear\", \"quadratic\", \"cubic\"]#, \"previous\", \"next\"]\n",
        "intp_co2 = []\n",
        "for k in kinds:\n",
        "  interpf = interpolate.interp1d(co2_select.time.to_numpy().astype(float), co2_select[\"ppm CO2\"], kind=k, fill_value=\"extrapolate\")\n",
        "  air_interp = interpf(cave_select.time.to_numpy().astype(float))\n",
        "  intp_co2.append(air_interp)\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "ax.plot(co2_select.index, co2_select[\"ppm CO2\"], \"o\")\n",
        "for i,l in zip(intp_co2, kinds):\n",
        "  ax.plot(cave_select.index, i, \"x-\", label=l)\n",
        "#ax.set_xlim(datetime.date(2015,10,17), datetime.date(2015,10,18))\n",
        "ax.set_xlim(datetime.datetime(2015,10,17, 9), datetime.datetime(2015,10,17,15))\n",
        "ax.set_ylim(425, 465)\n",
        "ax.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmO6uBAjecgr"
      },
      "source": [
        "#Part 4.6 - Introduction to data filtering - *Mini-lecture*\n",
        "\n",
        "*show problem - noisy data*\n",
        "\n",
        "*moving averages*\n",
        "\n",
        "*how: convolutions - also other filters*\n",
        "\n",
        "*other methods - e.g. fft - not here*\n",
        "\n",
        "*also mention complex filters, but let them explore in workshop*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OqJlpUZiFDH"
      },
      "source": [
        "#Part 4.7 - Data filtering excercise - *Workshop*\n",
        "We will apply a simple moving average filter on a noisy dataset to smooth it.\n",
        "\n",
        "You can either use a dataset of your choice (from the student submitted datasets), or use the following XRF core scanning data from an Antarctic sediment core: \"https://doi.pangaea.de/10.1594/PANGAEA.859980?format=textfile\" (V is particularly noisy).\n",
        "\n",
        "1. Construct a filter: a 1d numpy array with length n and each value being 1/n (so its sum is 1). The length must be an odd number.\n",
        "\n",
        "2. Apply the filter by convolving it with the data to be filtered using np.convolve.\n",
        "\n",
        "3. Plot the original and smoothed data.\n",
        "\n",
        "4. Experiment with different filter lengths.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc8Rc8D3fmo6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTgyLI9CfnFJ"
      },
      "source": [
        "#### ANSWER\n",
        "xdat = pd.read_csv(\"https://doi.pangaea.de/10.1594/PANGAEA.859980?format=textfile\", header=48, sep=\"\\t\")\n",
        "\n",
        "# Try plotting with bokeh so is interactive\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "# Call once to configure Bokeh to display plots inline in the notebook.\n",
        "output_notebook()\n",
        "\n",
        "p = figure()\n",
        "p.line(xdat[\"Depth [m]\"], xdat[\"V [cps]\"], line_color=\"black\")\n",
        "for fl, col in zip([3,5,9,15],[\"green\", \"indigo\", \"blue\", \"coral\"]):\n",
        "  filter = np.ones(fl ) / fl\n",
        "  Vf = np.convolve(xdat[\"V [cps]\"],filter)\n",
        "  p.line(xdat[\"Depth [m]\"], Vf[int((fl-1)/2):-int((fl-1)/2)], line_color=col)\n",
        "\n",
        "show(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdlfQJc8jQ-G"
      },
      "source": [
        "# Part 4.8 - Advanced filtering - *Mini-lecture*\n",
        "*mainly just different filter shapes are possible - introduce this idea*\n",
        "\n",
        "*also mention more advanced methods but do not explain in detail*\n",
        "\n",
        "*well, more advanced - not going to FFT, etc. yet!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4KbUjU_iU4I"
      },
      "source": [
        "# Part 4.9 - Week 4 Assignment\n",
        "\n",
        "**Task 1**\n",
        "\n",
        "Numpy provides some more complex filters here: https://numpy.org/doc/stable/reference/routines.window.html (window means filter in this context)\n",
        "Create a notebook where you apply these filters as well moving average filters to a noisy dataset. Experiment also with different filter lengths and comment on the differences and value of each method.\n",
        "\n",
        "**Task 2**\n",
        "\n",
        "Downsampling a noisy dataset by a significant amount (e.g. 10-100x) either by interpolation or just taking every nth data point, often leads to an unrepresentative representation of the original data. One solution is to first filter the data, then downsample the filtered dataset.\n",
        "\n",
        "Look back to the NGRIP dataset from Session 1. Resample it to 1 sample every 1 ky. First use the method we used above for the cave CO2 data, then try pre-filtering it (try different filters/sizes). \n",
        "\n",
        "\n",
        "**Submission**\n",
        "\n",
        "* EMAIL?OLAT?\n",
        "* The **deadline** is 23:59 on 10th November 2020.\n",
        "* This assignment comprises 5% of the assessment for the course. Marks are split between the two tasks and are awarded for effectively running the analyses, visualising, and discussing the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APqmSlZoipBJ"
      },
      "source": [
        "### ANSwERS\n",
        "dat_NGRIP = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/NGRIP_chronology_20.tab\", sep=\"\\t\", header=20)\n",
        "dat_NGRIP.columns = [\"age\", \"depth\", \"error\", \"d18O\"]\n",
        "dat_LR04 = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/LR04stack.txt\", sep=\"\\t\", header=3)\n",
        "dat_LR04.columns = [\"Time\", \"d18O\", \"error\"]\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYswHtXdjRdT"
      },
      "source": [
        "dat_NGRIP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clxzUk96jRRr"
      },
      "source": [
        "dat_LR04[0:41]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjcWrTZ2i2Wk"
      },
      "source": [
        "### ANSWerS\n",
        "ng_interp = interpolate.interp1d(dat_NGRIP.age, dat_NGRIP.d18O)\n",
        "ng_res = ng_interp(dat_LR04[0:41].Time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdolX9oFlQDU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf_Kln5ekPkX"
      },
      "source": [
        "### ANSWERS\n",
        "fig,ax = plt.subplots(figsize=(10,7))\n",
        "\n",
        "ax.plot(dat_NGRIP.age, dat_NGRIP.d18O)\n",
        "ax.plot(dat_LR04[0:41].Time, ng_res)\n",
        "#ax.plot(dat_LR04[0:41].Time, dat_LR04[0:41].d18O)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGLop8JrfZDx"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0bm5Y1VJorJ"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "from scipy import interpolate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-qkkrfbJqqM"
      },
      "source": [
        "air_temp = pd.read_excel(\"https://github.com/ds4geo/ds4geo/raw/master/data/timeseries/Au%C3%9Fenluft%2BEingangslabyrinth.xlsx\", sheet_name=\"Daten3\", usecols=[0,6], names=[\"time\", \"air_temp\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSWfplfXJ8gP"
      },
      "source": [
        "air_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peXGtCn8JuPT"
      },
      "source": [
        "cave_temp = pd.read_excel(\"https://github.com/ds4geo/ds4geo/raw/master/data/timeseries/Au%C3%9Fenluft%2BEingangslabyrinth.xlsx\", sheet_name=\"Daten3\", usecols=[8,9], names=[\"time\", \"cave_temp\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEfRiHNlRhHR"
      },
      "source": [
        "cave_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVHe3WnAlnpW"
      },
      "source": [
        "cave_temp.plot(\"time\", \"cave_temp\")\n",
        "air_temp.plot(\"time\", \"air_temp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joi9uTx8nxek"
      },
      "source": [
        "cave_co2 = pd.read_excel(r\"https://github.com/ds4geo/ds4geo/raw/master/data/timeseries/CO2%20_compiled.xlsx\",\n",
        "                         sheet_name=\"Data Stream (2)\", names=[\"time\", \"unknown\", \"d13C\", \"d18O\", \"ppm CO2\", \"ctime\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxgQH2VMGKvk"
      },
      "source": [
        "cave_co2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-QH0rCUGkA5"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(18,10))\n",
        "ax2 = ax.twinx()\n",
        "air_temp.plot(\"time\", \"air_temp\", ax=ax)\n",
        "cave_temp.plot(\"time\", \"cave_temp\", ax=ax)\n",
        "cave_co2.plot(\"time\", \"ppm CO2\", ax=ax2, color=\"r\")\n",
        "ax.set_xlim([datetime.date(2015,9,17), datetime.date(2015,11,20)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV3tvhbHGz4D"
      },
      "source": [
        "# get data only in range\n",
        "air_temp.index = air_temp.time # make time the index\n",
        "air_select = air_temp[\"2015-9-17\" : \"2015-11-20\"]\n",
        "\n",
        "cave_temp.index = cave_temp.time\n",
        "cave_select = cave_temp[\"2015-9-17\" : \"2015-11-20\"]\n",
        "\n",
        "cave_co2.index = cave_co2.time\n",
        "co2_select = cave_co2[\"2015-9-17\" : \"2015-11-20\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jk_uBaz9ZvB"
      },
      "source": [
        "# Check lengths\n",
        "print(\"air data shape:\", air_select.shape)\n",
        "print(\"cave data shape:\", cave_select.shape)\n",
        "print(\"co2 data shape:\", co2_select.shape)\n",
        "# All different"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPH4U71N9caQ"
      },
      "source": [
        "# Check sampling rate/timing\n",
        "print(\"air sampling rate:\",(air_select.index[1:] - air_select.index[:-1]).value_counts())\n",
        "print(\"cave sampling rate:\",(cave_select.index[1:] - cave_select.index[:-1]).value_counts())\n",
        "print(\"co2 sampling rate:\",(co2_select.index[1:] - co2_select.index[:-1]).value_counts())\n",
        "# air is 1 hour, cave temp is 15 mins, co2 is all over the place. Mostly around 5 minutes, but sometimes 10, or much longer.\n",
        "# If we resample to the cave temp 15 mins, then we are upsampling air temp, and downsampling the co2 data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9pC5now-S-V"
      },
      "source": [
        "# Testing upsampling of air temps\n",
        "kinds = [\"linear\", \"nearest\", \"zero\", \"slinear\", \"quadratic\", \"cubic\"]#, \"previous\", \"next\"]\n",
        "intp_air = []\n",
        "for k in kinds:\n",
        "  interpf = interpolate.interp1d(air_select.time.to_numpy().astype(float), air_select.air_temp, kind=k, fill_value=\"extrapolate\")\n",
        "  air_interp = interpf(cave_select.time.to_numpy().astype(float))\n",
        "  intp_air.append(air_interp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK9PTdbHa4A6"
      },
      "source": [
        "air_select.time.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgFEl7iD-W0o"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "for i,l in zip(intp_air, kinds):\n",
        "  ax.plot(cave_select.index, i, \"x-\", label=l)\n",
        "ax.plot(air_select.index, air_select.air_temp, \"o\")\n",
        "ax.set_xlim(datetime.date(2015,10,15), datetime.date(2015,10,16))\n",
        "ax.set_ylim(-4, 3)\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCrt8wBkBhN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VWpRFJWmap8"
      },
      "source": [
        "# Downsampling of co2 data\n",
        "kinds = [\"linear\", \"nearest\", \"zero\", \"slinear\", \"quadratic\", \"cubic\"]#, \"previous\", \"next\"]\n",
        "intp_co2 = []\n",
        "for k in kinds:\n",
        "  interpf = interpolate.interp1d(co2_select.time.to_numpy().astype(float), co2_select[\"ppm CO2\"], kind=k, fill_value=\"extrapolate\")\n",
        "  air_interp = interpf(cave_select.time.to_numpy().astype(float))\n",
        "  intp_co2.append(air_interp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Va6FZw2aC48"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "ax.plot(co2_select.index, co2_select[\"ppm CO2\"], \"o\")\n",
        "for i,l in zip(intp_co2, kinds):\n",
        "  ax.plot(cave_select.index, i, \"x-\", label=l)\n",
        "#ax.set_xlim(datetime.date(2015,10,17), datetime.date(2015,10,18))\n",
        "ax.set_xlim(datetime.datetime(2015,10,17, 9), datetime.datetime(2015,10,17,15))\n",
        "ax.set_ylim(425, 465)\n",
        "ax.legend()\n",
        "# alternative downsampling to be addressed while filtering in next section - e.g. mean of window, decimate, etc."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5roUZb0VACT"
      },
      "source": [
        "air_interp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWY1J1Y9amR3"
      },
      "source": [
        "# Now interpolated, can do direct comparisons:\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "ax.scatter( intp_air[0]-cave_select.cave_temp, intp_co2[0], marker=\"x\")\n",
        "#ax.scatter( intp_air[0], intp_co2[0], marker=\"x\")\n",
        "ax.set_ylim([375, 450])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRzFLdQOk8ld"
      },
      "source": [
        " cave_select.cave_temp.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_13xa-zcrHi"
      },
      "source": [
        "# Smoothing - need relevant data set to smooth!\n",
        "#scipy-cookbook.readthedocs.io/items/SignalSmooth.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx_AoGYPFb7o"
      },
      "source": [
        "xdat = pd.read_csv(\"https://doi.pangaea.de/10.1594/PANGAEA.859980?format=textfile\", header=48, sep=\"\\t\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jvC3DAPFi1S"
      },
      "source": [
        "xdat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCDrax8cFkqP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa70kdkOQR98"
      },
      "source": [
        "fig, ax1 = plt.subplots(figsize=(12,8))\n",
        "ax2 = ax1.twinx()\n",
        "ax3 = ax1.twinx()\n",
        "ax4 = ax1.twinx()\n",
        "xdat.plot(\"Depth [m]\", \"Al [cps]\", ax=ax1, color=\"C0\")\n",
        "xdat.plot(\"Depth [m]\", \"K [cps]\", ax=ax2, color=\"C1\")\n",
        "xdat.plot(\"Depth [m]\", \"Ti [cps]\", ax=ax3, color=\"C2\")\n",
        "xdat.plot(\"Depth [m]\", \"V [cps]\", ax=ax4, color=\"C3\")\n",
        "ax1.set_xlim(0.4,0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4Jj8lWtRguU"
      },
      "source": [
        "xdat.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCepK8VnR0px"
      },
      "source": [
        "filter_length = 5\n",
        "filter = np.ones(filter_length ) / filter_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLPO5EMq1ECt"
      },
      "source": [
        "filter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OphNx0R1diw"
      },
      "source": [
        "Vf = np.convolve(xdat[\"V [cps]\"],filter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85BKIalM1np9"
      },
      "source": [
        "Vf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZYcSEGE1pH_"
      },
      "source": [
        "%matplotlib notebook\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "ax.plot(xdat[\"Depth [m]\"], Vf[2:-2])\n",
        "ax.plot(xdat[\"Depth [m]\"], xdat[\"V [cps]\"])\n",
        "ax.set_xlim(0.4,0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9lzKq2O6iil"
      },
      "source": [
        "'''\n",
        "Rule of thumb:\n",
        "Matplotlib for static graphics, quick plotting and publication quality graphics\n",
        "Plotly for interactive or static/publication quality\n",
        "Bokeh for interactive/web plots\n",
        "Seaborn for quick but powerful stats plots\n",
        "Altair - different approach to making plots based on how we reason about data\n",
        "https://colab.research.google.com/notebooks/charts.ipynb#scrollTo=N-u5cYwpS-y0\n",
        "\n",
        "'''\n",
        "# Lets try bokeh\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "# Call once to configure Bokeh to display plots inline in the notebook.\n",
        "output_notebook()\n",
        "p = figure()\n",
        "p.line(xdat[\"Depth [m]\"], xdat[\"V [cps]\"], line_color=\"black\")\n",
        "for fl, col in zip([3,5,9,15],[\"green\", \"indigo\", \"blue\", \"coral\"]):\n",
        "  filter = np.ones(fl ) / fl\n",
        "  Vf = np.convolve(xdat[\"V [cps]\"],filter)\n",
        "  p.line(xdat[\"Depth [m]\"], Vf[int((fl-1)/2):-int((fl-1)/2)], line_color=col)\n",
        "\n",
        "show(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0jzHNOcIiQQ"
      },
      "source": [
        "p = figure()\n",
        "p.line(xdat[\"Depth [m]\"], xdat[\"V [cps]\"], line_color=\"black\")\n",
        "for fl, col in zip([3,5,9,15],[\"green\", \"indigo\", \"blue\", \"coral\"]):\n",
        "  filter = np.ones(fl ) / fl\n",
        "  Vf = np.convolve(xdat[\"V [cps]\"],filter)\n",
        "  p.line(xdat[\"Depth [m]\"], Vf[int((fl-1)/2):-int((fl-1)/2)], line_color=col)\n",
        "\n",
        "show(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8FZUJC9LSiQ"
      },
      "source": [
        "# But what about not simple flat moving averages... try different filter shapes from cookbook\n",
        "# Then also taking individual data points rather than proper smoothing.\n",
        "# Also non-overlapping windows?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hszlag5hVzfu"
      },
      "source": [
        "**Section X - Advanced Filters**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG87cuaSSb8p"
      },
      "source": [
        "# Compare results of these windows and also visualise the windows themselves: https://numpy.org/doc/stable/reference/routines.window.html"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}